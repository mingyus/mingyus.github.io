---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<!--{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}
-->
\* denotes equally contributing authors



**Peer-reviewed**

**Song M.\***, Bnaya Z.\*, Ma W.J. (2019) Sources of suboptimality in a minimalistic explore-exploit task. *Nature Human Behaviour* 3, 361–368. \[[pdf](http://mingyus.github.io/files/SongBnayaMa_NHB_2020.pdf)\] \[[code](https://github.com/mingyus/explore-exploit)\]

**Song M.\***, Wang X.\*, Zhang H., Li J. (2019) Proactive information sampling in value-based decision-making: deciding when and where to saccade. *Frontiers in Human Neuroscience*, 13, 35. \[[pdf](http://mingyus.github.io/files/SongWangZhangLi_fHN_2020.pdf)\]

Langdon A.J., **Song M.**, Niv Y. (2019) Uncovering the “state”: tracing the hidden state representations that structure learning and decision-making. *Behavioural Processes*, 103891 \[[pdf](http://mingyus.github.io/files/LangdonSongNiv_BP_2020.pdf)\]


**Conference Proceedings**

**Song M.**, Niv Y., Cai M.B. (2020) Learning multi-dimensional rules with probabilistic feedback via value-based serial hypothesis testing. *Workshop on Biological and Artificial Reinforcement Learning, Thirty-fourth Conference on Neural Information Processing Systems (Neurips)* [[talk](https://slideslive.com/38942371/learning-multidimensional-rules-via-valuebased-serial-hypothesis-testing)] [[pdf](http://mingyus.github.io/files/SongNivCai_Neurips_BARLworkshop_2020.pdf)]

**Song M.**, Niv Y., Cai M.B. (2020) Learning what is relevant for rewards via value-based serial hypothesis testing. *42nd Annual Virtual Meeting of the Cognitive Science Society (CogSci)* [talk] [[pdf](http://mingyus.github.io/files/SongNivCai_CogSci_2020.pdf)]

**Song M.**, Cai M.B, Niv Y. (2019) Learning what is relevant for rewards via value learning and hypothesis testing. *Computational and Cognitive Neuroscience Conference (CCN)*, Berlin, Germany [[poster](http://mingyus.github.io/files/SongCaiNiv_CNN_2019.pdf)]

**Song M.**, Langdon A., Takahashi Y., Schoenbaum G., Niv Y. (2019) Not smart enough: most rats fail to learn a parsimonious task representation. *The Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM)*, Montreal, QC, Canada [[poster](http://mingyus.github.io/files/SongLangdonNiv_RLDM_2019.pdf) & spotlight presentation]

**Song M.**, Bnaya Z., Ma W.J. (2017) History effects in a minimalistic explore-exploit task. *Computational and Cognitive Neuroscience Conference (CCN)*, New York, NY [[talk](https://www.youtube.com/watch?v=VQlRJJz5V3s)]

<br/>

<span style="color:grey; font-size:0.9em">The documents distributed here have been provided as a means to ensure timely dissemination of scholarly and technical work on a noncommercial basis. Copyright and all rights therein are are maintained by the authors or by other copyright holders, notwithstanding that they have offered their works here electronically. It is understood that all persons copying this information will adhere to the terms and constraints invoked by these copyrights. These works may not be reposted without the explicit permission of the copyright holder.</span>.